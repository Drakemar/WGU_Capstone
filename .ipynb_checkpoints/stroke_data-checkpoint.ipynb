{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "273565a4-61b3-4faf-955f-9303b95e4052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Loading dataset...\n",
      "\n",
      "🔹 Missing Values Before Processing:\n",
      " id                     0\n",
      "gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "ever_married           0\n",
      "work_type              0\n",
      "residence_type         0\n",
      "avg_glucose_level      0\n",
      "bmi                  201\n",
      "smoking_status         0\n",
      "stroke                 0\n",
      "dtype: int64\n",
      "\n",
      "✅ Missing Values Check (Post Processing): 0\n",
      "\n",
      "✅ Data Preprocessing Complete! No missing values found.\n",
      "🔹 Training Set: (5833, 22), Testing Set: (1022, 22)\n",
      "\n",
      "🔹 Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-16 01:09:34,749] A new study created in memory with name: no-name-621a3530-6e66-416b-b7c0-5a09203997af\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Optimizing XGBoost with Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-16 01:09:38,617] Trial 1 finished with value: 0.7931687242798353 and parameters: {'n_estimators': 169, 'max_depth': 4, 'learning_rate': 0.057913910462950906, 'subsample': 0.7643591601213698, 'colsample_bytree': 0.9148473410075804, 'scale_pos_weight': 10, 'gamma': 0.012676823119548698, 'reg_alpha': 0.4218085122719195, 'reg_lambda': 1.1946361204132034}. Best is trial 1 with value: 0.7931687242798353.\n",
      "[I 2025-03-16 01:09:38,786] Trial 14 finished with value: 0.7598148148148148 and parameters: {'n_estimators': 230, 'max_depth': 10, 'learning_rate': 0.24312699743500799, 'subsample': 0.9518125582037013, 'colsample_bytree': 0.6479870799100271, 'scale_pos_weight': 4, 'gamma': 0.700227789172651, 'reg_alpha': 1.8418741237292857, 'reg_lambda': 0.015847037942310377}. Best is trial 1 with value: 0.7931687242798353.\n",
      "[I 2025-03-16 01:09:38,951] Trial 4 finished with value: 0.7468724279835389 and parameters: {'n_estimators': 136, 'max_depth': 7, 'learning_rate': 0.1709845791154909, 'subsample': 0.6857177538656245, 'colsample_bytree': 0.7526058582349875, 'scale_pos_weight': 4, 'gamma': 0.9473259703069306, 'reg_alpha': 0.12023151222169838, 'reg_lambda': 0.01571485096376849}. Best is trial 1 with value: 0.7931687242798353.\n",
      "[I 2025-03-16 01:09:39,019] Trial 15 finished with value: 0.8256378600823046 and parameters: {'n_estimators': 240, 'max_depth': 3, 'learning_rate': 0.01905823892710973, 'subsample': 0.7875926707011945, 'colsample_bytree': 0.8939654191906314, 'scale_pos_weight': 6, 'gamma': 0.03307531182509639, 'reg_alpha': 3.9234203959821907, 'reg_lambda': 1.8990435775825594}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:39,470] Trial 11 finished with value: 0.7495267489711934 and parameters: {'n_estimators': 245, 'max_depth': 3, 'learning_rate': 0.22149059554406242, 'subsample': 0.613281976650016, 'colsample_bytree': 0.985354727651603, 'scale_pos_weight': 10, 'gamma': 0.06547862362005072, 'reg_alpha': 0.04559373843653908, 'reg_lambda': 0.03661417807659701}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:39,787] Trial 13 finished with value: 0.7509670781893004 and parameters: {'n_estimators': 141, 'max_depth': 6, 'learning_rate': 0.2772237136321838, 'subsample': 0.6952698405404032, 'colsample_bytree': 0.8543044785176477, 'scale_pos_weight': 2, 'gamma': 0.08857284936913441, 'reg_alpha': 0.04466031792507935, 'reg_lambda': 2.3483298734507905}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:40,882] Trial 20 finished with value: 0.7687860082304527 and parameters: {'n_estimators': 231, 'max_depth': 6, 'learning_rate': 0.14103079122940118, 'subsample': 0.8511930247701414, 'colsample_bytree': 0.9445181251702095, 'scale_pos_weight': 8, 'gamma': 0.9164485993449526, 'reg_alpha': 1.435708014176602, 'reg_lambda': 0.41193461029111594}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:41,756] Trial 17 finished with value: 0.752366255144033 and parameters: {'n_estimators': 301, 'max_depth': 5, 'learning_rate': 0.19672017423365432, 'subsample': 0.8937198902128984, 'colsample_bytree': 0.7895128326474798, 'scale_pos_weight': 6, 'gamma': 0.3225801251044888, 'reg_alpha': 4.2075818821297215, 'reg_lambda': 2.059345500078191}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:43,141] Trial 5 finished with value: 0.7510905349794239 and parameters: {'n_estimators': 362, 'max_depth': 5, 'learning_rate': 0.2519475624510781, 'subsample': 0.8562986103745687, 'colsample_bytree': 0.7368280453994216, 'scale_pos_weight': 8, 'gamma': 0.17045560942030366, 'reg_alpha': 5.958472779999874, 'reg_lambda': 0.06660701326741543}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:44,514] Trial 21 finished with value: 0.8084362139917695 and parameters: {'n_estimators': 495, 'max_depth': 3, 'learning_rate': 0.017676316509953677, 'subsample': 0.6035031856114504, 'colsample_bytree': 0.720207039368326, 'scale_pos_weight': 2, 'gamma': 0.016250067361766492, 'reg_alpha': 0.021281816256775395, 'reg_lambda': 0.2817259919225652}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:45,257] Trial 2 finished with value: 0.7860905349794238 and parameters: {'n_estimators': 239, 'max_depth': 8, 'learning_rate': 0.02900720199255933, 'subsample': 0.668215900327885, 'colsample_bytree': 0.6585756883287229, 'scale_pos_weight': 6, 'gamma': 0.01164218807707556, 'reg_alpha': 5.546025637588427, 'reg_lambda': 0.2840227568747466}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:45,495] Trial 18 finished with value: 0.7797736625514403 and parameters: {'n_estimators': 333, 'max_depth': 6, 'learning_rate': 0.029662339680297987, 'subsample': 0.6001662357977252, 'colsample_bytree': 0.8876102813803379, 'scale_pos_weight': 7, 'gamma': 0.20890464593382163, 'reg_alpha': 1.3404086489569036, 'reg_lambda': 0.44067965488651667}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:45,907] Trial 16 finished with value: 0.7582304526748971 and parameters: {'n_estimators': 228, 'max_depth': 9, 'learning_rate': 0.04844984911241123, 'subsample': 0.943237724158656, 'colsample_bytree': 0.8024439656851461, 'scale_pos_weight': 8, 'gamma': 0.03463281131008174, 'reg_alpha': 0.05537844795388236, 'reg_lambda': 0.021528094334733735}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:46,793] Trial 22 finished with value: 0.7801440329218107 and parameters: {'n_estimators': 171, 'max_depth': 10, 'learning_rate': 0.016923555589987455, 'subsample': 0.8007340950160641, 'colsample_bytree': 0.8666919218044349, 'scale_pos_weight': 7, 'gamma': 0.2969077754339649, 'reg_alpha': 1.6651994561476813, 'reg_lambda': 0.0724740841213066}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:46,841] Trial 29 finished with value: 0.8030246913580247 and parameters: {'n_estimators': 241, 'max_depth': 4, 'learning_rate': 0.03470091607895525, 'subsample': 0.9654614809458635, 'colsample_bytree': 0.8782989002096986, 'scale_pos_weight': 6, 'gamma': 0.020541177455251323, 'reg_alpha': 7.175771745217258, 'reg_lambda': 0.038203294248717636}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:47,261] Trial 8 finished with value: 0.7691769547325104 and parameters: {'n_estimators': 320, 'max_depth': 8, 'learning_rate': 0.020647474273435513, 'subsample': 0.9681033452326397, 'colsample_bytree': 0.7875537308488719, 'scale_pos_weight': 8, 'gamma': 0.4686766853160628, 'reg_alpha': 0.08085763594494151, 'reg_lambda': 0.3694353774777474}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:47,914] Trial 9 finished with value: 0.7538477366255144 and parameters: {'n_estimators': 283, 'max_depth': 9, 'learning_rate': 0.048730361285276316, 'subsample': 0.6412481814088759, 'colsample_bytree': 0.6284497382738763, 'scale_pos_weight': 4, 'gamma': 0.014970230382498766, 'reg_alpha': 0.15630326330873037, 'reg_lambda': 0.016971715185190583}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:48,102] Trial 27 finished with value: 0.7662345679012346 and parameters: {'n_estimators': 423, 'max_depth': 4, 'learning_rate': 0.05530652166933434, 'subsample': 0.6077465494895506, 'colsample_bytree': 0.8954852662506229, 'scale_pos_weight': 4, 'gamma': 0.25221883590540617, 'reg_alpha': 0.10586356288715242, 'reg_lambda': 0.021087642412202873}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:48,110] Trial 6 finished with value: 0.8038477366255142 and parameters: {'n_estimators': 420, 'max_depth': 6, 'learning_rate': 0.0102810241204181, 'subsample': 0.8466281377082351, 'colsample_bytree': 0.8841066104504822, 'scale_pos_weight': 3, 'gamma': 0.014811623088693203, 'reg_alpha': 0.03032984863782263, 'reg_lambda': 0.8947459956205066}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:48,243] Trial 0 finished with value: 0.7423045267489712 and parameters: {'n_estimators': 447, 'max_depth': 7, 'learning_rate': 0.12511032626039478, 'subsample': 0.9008574886123546, 'colsample_bytree': 0.6534185895821243, 'scale_pos_weight': 7, 'gamma': 0.11447675054604681, 'reg_alpha': 0.1946947908502479, 'reg_lambda': 0.5853310267161326}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:48,915] Trial 3 finished with value: 0.7368106995884774 and parameters: {'n_estimators': 425, 'max_depth': 10, 'learning_rate': 0.16388506614345857, 'subsample': 0.9687765005302539, 'colsample_bytree': 0.956400378136364, 'scale_pos_weight': 6, 'gamma': 0.024006823109721506, 'reg_alpha': 0.012114283261878, 'reg_lambda': 0.10590551275145009}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:49,312] Trial 26 finished with value: 0.7547942386831276 and parameters: {'n_estimators': 308, 'max_depth': 8, 'learning_rate': 0.06264872417246743, 'subsample': 0.7561457625010001, 'colsample_bytree': 0.6401126047816633, 'scale_pos_weight': 6, 'gamma': 0.10411607022844664, 'reg_alpha': 2.492917511903532, 'reg_lambda': 0.10541298711651284}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:49,776] Trial 24 finished with value: 0.7653292181069958 and parameters: {'n_estimators': 303, 'max_depth': 9, 'learning_rate': 0.01983787804503649, 'subsample': 0.685601363293835, 'colsample_bytree': 0.6218520242612832, 'scale_pos_weight': 10, 'gamma': 0.014957726188105262, 'reg_alpha': 1.634943877615595, 'reg_lambda': 0.040316860298822456}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:49,911] Trial 28 finished with value: 0.7601028806584362 and parameters: {'n_estimators': 415, 'max_depth': 5, 'learning_rate': 0.06588165170700637, 'subsample': 0.7570808597014687, 'colsample_bytree': 0.7657685055020427, 'scale_pos_weight': 2, 'gamma': 0.2101949949587465, 'reg_alpha': 0.09784626737044742, 'reg_lambda': 1.4246484636152943}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:50,117] Trial 12 finished with value: 0.7320987654320988 and parameters: {'n_estimators': 495, 'max_depth': 8, 'learning_rate': 0.23899376712635315, 'subsample': 0.9591668302010956, 'colsample_bytree': 0.6925719655294326, 'scale_pos_weight': 4, 'gamma': 0.015286946592523835, 'reg_alpha': 0.20792280335682076, 'reg_lambda': 9.537997191805317}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:50,207] Trial 7 finished with value: 0.7624691358024692 and parameters: {'n_estimators': 370, 'max_depth': 10, 'learning_rate': 0.069625490374581, 'subsample': 0.8532218661804368, 'colsample_bytree': 0.7461527655653614, 'scale_pos_weight': 3, 'gamma': 0.01265453627695931, 'reg_alpha': 4.618679087528089, 'reg_lambda': 0.8563954100428347}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:50,253] Trial 25 finished with value: 0.7381893004115226 and parameters: {'n_estimators': 347, 'max_depth': 9, 'learning_rate': 0.1080264513059807, 'subsample': 0.6985351906392698, 'colsample_bytree': 0.7646664462343276, 'scale_pos_weight': 3, 'gamma': 0.013738738664168191, 'reg_alpha': 0.35709585025423696, 'reg_lambda': 0.24603050966886653}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:50,272] Trial 10 finished with value: 0.7610905349794239 and parameters: {'n_estimators': 357, 'max_depth': 10, 'learning_rate': 0.04558314795364122, 'subsample': 0.8564343957637623, 'colsample_bytree': 0.6592528614435589, 'scale_pos_weight': 3, 'gamma': 0.015945924097326165, 'reg_alpha': 0.16496913889402026, 'reg_lambda': 0.10100250970175026}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:50,392] Trial 19 finished with value: 0.7908024691358024 and parameters: {'n_estimators': 469, 'max_depth': 8, 'learning_rate': 0.011268733159560397, 'subsample': 0.9174596691278626, 'colsample_bytree': 0.9264196092226742, 'scale_pos_weight': 2, 'gamma': 0.2446191938644152, 'reg_alpha': 0.03422549089900101, 'reg_lambda': 0.030066521707865536}. Best is trial 15 with value: 0.8256378600823046.\n",
      "[I 2025-03-16 01:09:50,472] Trial 23 finished with value: 0.7491152263374485 and parameters: {'n_estimators': 488, 'max_depth': 7, 'learning_rate': 0.03805146753601507, 'subsample': 0.7442078989279639, 'colsample_bytree': 0.6317182707815099, 'scale_pos_weight': 9, 'gamma': 0.09891019489549757, 'reg_alpha': 1.4411227624656149, 'reg_lambda': 0.4800944466366938}. Best is trial 15 with value: 0.8256378600823046.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Best XGBoost Parameters: {'n_estimators': 240, 'max_depth': 3, 'learning_rate': 0.01905823892710973, 'subsample': 0.7875926707011945, 'colsample_bytree': 0.8939654191906314, 'scale_pos_weight': 6, 'gamma': 0.03307531182509639, 'reg_alpha': 3.9234203959821907, 'reg_lambda': 1.8990435775825594}\n",
      "\n",
      "🔹 Training Logistic Regression...\n",
      "\n",
      "🔹 Model Comparison Summary:\n",
      "\n",
      "Random Forest → Accuracy: 0.8405 | AUC-ROC: 0.7781 | Precision: 0.1447 | Recall: 0.4600 | F1-Score: 0.2201\n",
      "\n",
      "XGBoost (Fine-Tuned) → Accuracy: 0.6399 | AUC-ROC: 0.8256 | Precision: 0.1045 | Recall: 0.8400 | F1-Score: 0.1858\n",
      "\n",
      "Logistic Regression → Accuracy: 0.7720 | AUC-ROC: 0.7948 | Precision: 0.1383 | Recall: 0.7000 | F1-Score: 0.2310\n",
      "\n",
      "✅ Best XGBoost model saved as 'best_stroke_prediction_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna  # Bayesian Optimization for XGBoost\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, roc_auc_score, confusion_matrix,\n",
    "    roc_curve, precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer  # Handle missing values\n",
    "import joblib  # Save the best model\n",
    "\n",
    "# ========================\n",
    "# 1️⃣ Load & Preprocess Data\n",
    "# ========================\n",
    "print(\"\\n🔹 Loading dataset...\")\n",
    "df = pd.read_csv(\"stroke_data.csv\")  # Ensure the file is in the correct directory\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# 🔹 Check for missing values before handling them\n",
    "print(\"\\n🔹 Missing Values Before Processing:\\n\", df.isnull().sum())\n",
    "\n",
    "# Handle missing values for BMI\n",
    "df['bmi'] = df['bmi'].fillna(df['bmi'].median())\n",
    "\n",
    "# 🔹 Feature Engineering: Create new meaningful features\n",
    "df['bmi_category'] = pd.cut(df['bmi'], bins=[-np.inf, 18.5, 24.9, 29.9, np.inf], labels=[0, 1, 2, 3]).astype(int)\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 30, 50, 70, np.inf], labels=[0, 1, 2, 3]).astype(int)\n",
    "df['hypertension_glucose'] = df['hypertension'] * df['avg_glucose_level']\n",
    "\n",
    "# 🔹 Ensure smoking_status is properly mapped to numerical values (handle NaN)\n",
    "df['smoking_status'] = df['smoking_status'].map({'never smoked': 0, 'formerly smoked': 1, 'smokes': 2}).fillna(0).astype(int)\n",
    "df['heart_smoking'] = df['heart_disease'] * df['smoking_status']\n",
    "\n",
    "# Convert categorical variables to numerical\n",
    "df = pd.get_dummies(df, columns=['gender', 'work_type', 'residence_type', 'bmi_category', 'age_group'], drop_first=True)\n",
    "df['ever_married'] = df['ever_married'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# 🔹 Handle any remaining missing values using SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 🔹 Ensure categorical and integer columns retain their types after imputation\n",
    "for col in df.columns:\n",
    "    if df[col].dtype in [\"int64\", \"bool\"]:\n",
    "        df_imputed[col] = df_imputed[col].astype(int)\n",
    "\n",
    "df = df_imputed  # Overwrite the original DataFrame with cleaned data\n",
    "\n",
    "# 🔹 Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "numeric_features = ['age', 'bmi', 'avg_glucose_level', 'hypertension_glucose']\n",
    "df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = df.drop(columns=['stroke', 'id'], errors='ignore')  # Drop 'id' if it exists\n",
    "y = df['stroke']\n",
    "\n",
    "# 🔹 Check for any remaining missing values\n",
    "print(\"\\n✅ Missing Values Check (Post Processing):\", X.isnull().sum().sum())\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\n✅ Data Preprocessing Complete! No missing values found.\")\n",
    "print(f\"🔹 Training Set: {X_train_smote.shape}, Testing Set: {X_test.shape}\")\n",
    "\n",
    "# ========================\n",
    "# 2️⃣ Train a Random Forest Model\n",
    "# ========================\n",
    "print(\"\\n🔹 Training Random Forest...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=10, class_weight=\"balanced\")\n",
    "rf_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_prob_rf = rf_model.predict_proba(X_test)[:, 1]  # Probability scores for ROC-AUC\n",
    "\n",
    "# ========================\n",
    "# 3️⃣ Fine-Tune XGBoost Using Optuna\n",
    "# ========================\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'scale_pos_weight': trial.suggest_int('scale_pos_weight', 2, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0.01, 1.0, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 10.0, log=True)\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params, random_state=42)\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    return roc_auc_score(y_test, y_prob)  # Optimize AUC-ROC\n",
    "\n",
    "print(\"\\n🔹 Optimizing XGBoost with Optuna...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30, n_jobs=-1)\n",
    "\n",
    "# Train XGBoost with best parameters\n",
    "best_params_xgb = study.best_trial.params\n",
    "print(\"\\n✅ Best XGBoost Parameters:\", best_params_xgb)\n",
    "\n",
    "best_xgb = XGBClassifier(**best_params_xgb, random_state=42)\n",
    "best_xgb.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "y_prob_xgb = best_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ========================\n",
    "# 4️⃣ Train a Logistic Regression Model\n",
    "# ========================\n",
    "print(\"\\n🔹 Training Logistic Regression...\")\n",
    "log_reg_model = LogisticRegression(class_weight=\"balanced\", max_iter=500, random_state=42)\n",
    "log_reg_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_log = log_reg_model.predict(X_test)\n",
    "y_prob_log = log_reg_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ========================\n",
    "# 5️⃣ Compare Model Performances\n",
    "# ========================\n",
    "models = {\n",
    "    \"Random Forest\": (y_pred_rf, y_prob_rf),\n",
    "    \"XGBoost (Fine-Tuned)\": (y_pred_xgb, y_prob_xgb),\n",
    "    \"Logistic Regression\": (y_pred_log, y_prob_log),\n",
    "}\n",
    "\n",
    "print(\"\\n🔹 Model Comparison Summary:\")\n",
    "for model_name, (y_pred, y_prob) in models.items():\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name} → Accuracy: {accuracy:.4f} | AUC-ROC: {auc:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1-Score: {f1:.4f}\")\n",
    "\n",
    "# ========================\n",
    "# 6️⃣ Save the Best Model\n",
    "# ========================\n",
    "joblib.dump(best_xgb, \"best_stroke_prediction_model.pkl\")\n",
    "print(\"\\n✅ Best XGBoost model saved as 'best_stroke_prediction_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3058531-7f9c-46d4-ac0b-9484e25568b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e34fb-233d-40c2-b934-0171e6e1e197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc6daf-de51-484f-82bf-74e32f7d0d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af926721-ec9c-4cb9-9f5b-c5f92a31e140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77f898b-5ed1-458b-9aff-a93dfc75d7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c2364-ce7f-477e-ba5a-dc98ae39b2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
